{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318c8070-fbb2-4e13-841c-0a444d0d8f46",
   "metadata": {},
   "source": [
    "# Introduction to LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd97ab72-93b0-4f2a-8bda-5c74cf990e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3368b",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e43dd",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f488b51",
   "metadata": {},
   "source": [
    "### Set API key for Groq\n",
    "Click [here](https://console.groq.com/keys) to create API key for Groq, if not already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f8bf66b-a0a2-4edf-ad28-c0fe266c9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, re, getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv( override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91837874-8c93-4331-9ad8-1bcd68d9dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b71624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"TEST_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"TEST_API_KEY\"] = getpass.getpass(\"TEST API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "408e4cc7-6ce5-4cb6-af3f-8ac923dbf6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "if os.environ[\"GROQ_API_KEY\"]:\n",
    "    print(f\"Groq API Key exists and begins {os.environ[\"GROQ_API_KEY\"][:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b9342",
   "metadata": {},
   "source": [
    "## LangChain Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d44e67",
   "metadata": {},
   "source": [
    "### LLM / ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c4e08e3-b15e-48ac-bdb6-86fe1839f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4df3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LangChain\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model_name = \"llama-3.1-8b-instant\"\n",
    "llm = init_chat_model(model_name, model_provider=\"groq\") #Other Llama alternatives available are llama3-8b-8192, llama-3.3-70b-versatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d8fd4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"ECG stands for Electrocardiogram. It is a medical test that measures the electrical activity of the heart over a period of time. The test records the heart's electrical signals as they travel through the heart muscle, allowing doctors to diagnose and monitor various heart conditions.\\n\\nDuring an ECG, a series of electrodes are placed on the chest, arms, and legs to record the heart's electrical activity. The electrodes detect the tiny electrical signals generated by the heart's contractions and transmit them to a machine that records the signals on a graph. The graph shows the heart's rhythm, rate, and any abnormalities in the electrical activity.\\n\\nAn ECG can detect a range of heart conditions, including:\\n\\n1. Arrhythmias (abnormal heart rhythms)\\n2. Heart attacks (myocardial infarctions)\\n3. Heart failure\\n4. Cardiac arrhythmias\\n5. Electrolyte imbalances\\n6. Heart valve problems\\n7. Cardiac hypertrophy (enlargement of the heart muscle)\\n\\nThere are different types of ECGs, including:\\n\\n1. Resting ECG (R-ECG): Performed while the patient is at rest.\\n2. Stress ECG (S-ECG): Performed while the patient is exercising or under stress.\\n3. Holter monitoring: A portable ECG that records the heart's activity over a 24-hour period.\\n4. Event monitoring: A portable ECG that records the heart's activity during a specific event, such as a heart attack.\\n\\nOverall, an ECG is a simple, non-invasive test that provides valuable information about the heart's electrical activity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 40, 'total_tokens': 371, 'completion_time': 0.682360826, 'prompt_time': 0.002281776, 'queue_time': 0.047936014, 'total_time': 0.684642602}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8ab2e50475', 'finish_reason': 'stop', 'logprobs': None}, id='run--258f4b48-207a-4068-8974-236c93eb251a-0', usage_metadata={'input_tokens': 40, 'output_tokens': 331, 'total_tokens': 371})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = llm.invoke(\"what is ECG?\")\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "498e9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of response <class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(\"type of response\", type(llm_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edc8d4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 40, 'output_tokens': 331, 'total_tokens': 371}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(llm_response.content)\n",
    "# display(llm_response.response_metadata)\n",
    "display(llm_response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abff1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a corrected version of the text:\n",
      "\n",
      "\"Hey, can you send me that report by tomorrow, please?\"\n",
      "\n",
      "I made the following corrections:\n",
      "\n",
      "* Added a comma after \"tomorrow\" to separate the main clause from the request.\n",
      "* Changed \"thx\" to \"please,\" which is a more polite and formal way to end the message.\n",
      "* Added a question mark at the end to indicate that the text is a question.\n",
      "\n",
      "However, considering the context, it seems like the message might be more suitable as a statement:\n",
      "\n",
      "\"Hey, I'd appreciate it if you could send me that report by tomorrow, please.\"\n",
      "\n",
      "This revised message still conveys the request but in a more polite and formal tone.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\\n",
    "                  Ensure proper sentence structure, clarity, and readability.\\\n",
    "                  Retain the core message of the original text while making the necessary corrections\"),\n",
    "    HumanMessage(content=\"hey can you send me that report by tomorrow thx\"),\n",
    "]\n",
    "\n",
    "ai_response = llm.invoke(messages)\n",
    "print(ai_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4662794-34a0-4542-a7e4-ac44ce778acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followup conversation\n",
    "messages.append(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21578799-a1bb-483c-b580-2c143c141b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ask a follow-up question\n",
    "messages.append(HumanMessage(content=\"can you make the tone a bit informal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b988b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a revised version of the message with a slightly more informal tone:\n",
      "\n",
      "\"Hey, can you send me that report by tomorrow? That'd be a huge help, thanks.\"\n",
      "\n",
      "I made the following changes to create a more informal tone:\n",
      "\n",
      "* Removed the \"please\" and replaced it with \"thanks,\" which is a more casual way to express gratitude.\n",
      "* Added a phrase (\"That'd be a huge help\") to make the message more conversational and friendly.\n",
      "* Kept the question mark at the end to maintain a polite and considerate tone.\n",
      "\n",
      "Alternatively, if you want it to be even more casual, you could simplify the message to:\n",
      "\n",
      "\"Hey, can you send me that report by tomorrow? Thanks!\"\n",
      "\n",
      "This version still conveys the request and shows appreciation for the person's help, but in a more relaxed and friendly way.\n"
     ]
    }
   ],
   "source": [
    "ai_response = llm.invoke(messages)\n",
    "# print(ai_response)\n",
    "print(ai_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de82ae",
   "metadata": {},
   "source": [
    "#### Doing without LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff4947c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without LangChain - how would we initialize our LLM?\n",
    "from openai import OpenAI\n",
    "\n",
    "model_name = \"llama-3.1-8b-instant\"\n",
    "llm_api = OpenAI(api_key=os.environ[\"GROQ_API_KEY\"], base_url=\"https://api.groq.com/openai/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c19d32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Below is LangChain's messages format\n",
    "# messages = [\n",
    "\n",
    "#     SystemMessage(content=\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\\n",
    "#                   Ensure proper sentence structure, clarity, and readability.\\\n",
    "#                   Retain the core message of the original text while making the necessary corrections\"),\n",
    "#     HumanMessage(content=\"hey can you send me that report by tomorrow thx\"),\n",
    "# ]\n",
    "\n",
    "#Below is messages in OpenAI format\n",
    "messages_openai = [\n",
    "    {'role':\"system\", 'content':\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\\n",
    "     Ensure proper sentence structure, clarity, and readability.\\\n",
    "     Retain the core message of the original text while making the necessary corrections\"},\n",
    "     \n",
    "     {'role':\"user\", 'content':\"hey can you send me that report by tomorrow thx\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c95364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response_openai = llm_api.chat.completions.create(model= model_name,\n",
    "                                messages=messages_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39e59642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-d10d8052-4d2e-41d5-803c-1907034d3f8f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='There is a bit of informal tone to the request. Here\\'s a revised version with proper spelling, grammar, punctuation, and sentence structure:\\n\\n\"Could you please send me the report by tomorrow? Thank you.\"', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1751520543, model='llama-3.1-8b-instant', object='chat.completion', service_tier=None, system_fingerprint='fp_0f5c9bc037', usage=CompletionUsage(completion_tokens=43, prompt_tokens=89, total_tokens=132, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.049183392000000006, prompt_time=0.005491698, completion_time=0.095450679, total_time=0.100942377), usage_breakdown=None, x_groq={'id': 'req_01jz7c50czfqkb18tpsv44y5s8'})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b13b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a bit of informal tone to the request. Here's a revised version with proper spelling, grammar, punctuation, and sentence structure:\n",
      "\n",
      "\"Could you please send me the report by tomorrow? Thank you.\"\n"
     ]
    }
   ],
   "source": [
    "ai_response_openai_formatted = ai_response_openai.choices[0].message.content\n",
    "print(ai_response_openai_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcdffd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Detect and correct all spelling, grammatical, and punctuation errors in the provided text.     Ensure proper sentence structure, clarity, and readability.     Retain the core message of the original text while making the necessary corrections'},\n",
       " {'role': 'user',\n",
       "  'content': 'hey can you send me that report by tomorrow thx'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91cff65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the AI message\n",
    "messages_openai.append(\n",
    "    {'role': \"assistant\",\n",
    "     'content': ai_response_openai_formatted}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b94f587c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Detect and correct all spelling, grammatical, and punctuation errors in the provided text.     Ensure proper sentence structure, clarity, and readability.     Retain the core message of the original text while making the necessary corrections'},\n",
       " {'role': 'user',\n",
       "  'content': 'hey can you send me that report by tomorrow thx'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'There is a bit of informal tone to the request. Here\\'s a revised version with proper spelling, grammar, punctuation, and sentence structure:\\n\\n\"Could you please send me the report by tomorrow? Thank you.\"'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "267fa547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ask a follow-up question\n",
    "#LangChain version below\n",
    "# messages.append(HumanMessage(content=\"can you make the tone a bit informal\"))\n",
    "\n",
    "#OpenAI version below\n",
    "messages_openai.append(\n",
    "    {'role':\"user\",\n",
    "     'content':\"can you make the tone a bit informal\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65ecf978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Detect and correct all spelling, grammatical, and punctuation errors in the provided text.     Ensure proper sentence structure, clarity, and readability.     Retain the core message of the original text while making the necessary corrections'},\n",
       " {'role': 'user',\n",
       "  'content': 'hey can you send me that report by tomorrow thx'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'There is a bit of informal tone to the request. Here\\'s a revised version with proper spelling, grammar, punctuation, and sentence structure:\\n\\n\"Could you please send me the report by tomorrow? Thank you.\"'},\n",
       " {'role': 'user', 'content': 'can you make the tone a bit informal'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d208299",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response_openai = llm_api.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages_openai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09fc81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ai_response_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76b8f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a revised version with a slightly more informal tone:\n",
      "\n",
      "\"Hey, would you be able to send me the report by tomorrow? Thanks!\"\n"
     ]
    }
   ],
   "source": [
    "print(ai_response_openai.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55a15ed3-1162-4d79-bbf0-60da439e12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain concept of context length here - Context length = input tokens + completion tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f9d09",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b2bb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc74a4",
   "metadata": {},
   "source": [
    "*StrOutputParser* is a runnable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4d28206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s the revised message:\\n\\n\"Hey, can you get me that report by tomorrow, please?\"\\n\\nI made the following changes to make the tone less formal:\\n\\n* Removed the phrase \"I\\'d appreciate it if,\" which is a bit more formal.\\n* Changed the wording to \"get me\" instead of \"send me,\" which is a more casual way to ask for something.\\n\\nHowever, if you want to make it even more informal, you could try:\\n\\n\"Hey, do you think you could send the report by tomorrow?\"\\n\\nThis version is a bit more relaxed and conversational.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(messages)\n",
    "\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "681fdd4f-84ef-41da-906b-503ab3e7e44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s the revised message:\\n\\n\"Hey, can you get me that report by tomorrow, please?\"\\n\\nI made the following changes to make the tone less formal:\\n\\n* Removed the phrase \"I\\'d appreciate it if,\" which is a bit more formal.\\n* Changed the wording to \"get me\" instead of \"send me,\" which is a more casual way to ask for something.\\n\\nHowever, if you want to make it even more informal, you could try:\\n\\n\"Hey, do you think you could send the report by tomorrow?\"\\n\\nThis version is a bit more relaxed and conversational.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 249, 'total_tokens': 367, 'completion_time': 0.196930076, 'prompt_time': 0.014841967, 'queue_time': 0.04843691900000001, 'total_time': 0.211772043}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8ab2e50475', 'finish_reason': 'stop', 'logprobs': None}, id='run--bbceeb0d-adcf-4eed-acf8-0aba034c234e-0', usage_metadata={'input_tokens': 249, 'output_tokens': 118, 'total_tokens': 367})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b545842-17e9-4e7e-9c48-05914c890c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"You are an expert in writing analysis. You will receive a message from a user, and your job is to evaluate the text based on the following attributes:\n",
    "1. clarity: Is the message clear, or unclear?\n",
    "2. grammar_quality: Are there any grammatical issues? Possible values: correct, minor issues, major issues.\n",
    "3. tone: Analyze whether the tone is neutral, formal, or informal.\n",
    "4. suggestions: Offer brief improvement suggestions for clarity, grammar, or tone.\n",
    "\n",
    "Return a structured JSON object with these four attributes.\"\"\"),\n",
    "    HumanMessage(content=\"Hey, could you please send me that report by tomorrow? Thank you.\")\n",
    "]\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8528ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s the analysis of the message:\\n\\n```json\\n{\\n  \"clarity\": \"unclear\",\\n  \"grammar_quality\": \"minor issues\",\\n  \"tone\": \"informal\",\\n  \"suggestions\": [\\n    \"For clarity, please specify what report you are referring to.\",\\n    \"Consider rephrasing to \\'I would greatly appreciate it if you could send me the report by tomorrow\\' for a clearer tone.\",\\n    \"There is a misplaced period at the end of the message. For better grammar, consider ending the message with a period or a question mark.\"\\n  ]\\n}\\n```\\n\\nThis analysis suggests that the message is unclear due to the lack of specifics about the report. The tone is informal, which may be suitable for a personal or casual conversation but may not be suitable for a formal request. There are minor grammatical issues, such as the misplaced period at the end of the message.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 159, 'total_tokens': 343, 'completion_time': 0.354402751, 'prompt_time': 0.009368259, 'queue_time': 0.052196248, 'total_time': 0.36377101}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_510c177af0', 'finish_reason': 'stop', 'logprobs': None}, id='run--693ed7b8-8211-4ae5-a12d-efe9c80d1046-0', usage_metadata={'input_tokens': 159, 'output_tokens': 184, 'total_tokens': 343})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "91a8e920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s the analysis of the message:\\n\\n```json\\n{\\n  \"clarity\": \"unclear\",\\n  \"grammar_quality\": \"minor issues\",\\n  \"tone\": \"informal\",\\n  \"suggestions\": [\\n    \"For clarity, please specify what report you are referring to.\",\\n    \"Consider rephrasing to \\'I would greatly appreciate it if you could send me the report by tomorrow\\' for a clearer tone.\",\\n    \"There is a misplaced period at the end of the message. For better grammar, consider ending the message with a period or a question mark.\"\\n  ]\\n}\\n```\\n\\nThis analysis suggests that the message is unclear due to the lack of specifics about the report. The tone is informal, which may be suitable for a personal or casual conversation but may not be suitable for a formal request. There are minor grammatical issues, such as the misplaced period at the end of the message.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea4c7a8a-9eab-4b67-a5ba-717993a8b668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clarity': 'unclear',\n",
       " 'grammar_quality': 'minor issues',\n",
       " 'tone': 'informal',\n",
       " 'suggestions': ['For clarity, please specify what report you are referring to.',\n",
       "  \"Consider rephrasing to 'I would greatly appreciate it if you could send me the report by tomorrow' for a clearer tone.\",\n",
       "  'There is a misplaced period at the end of the message. For better grammar, consider ending the message with a period or a question mark.']}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = JsonOutputParser().invoke(response.content)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed5a4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json{\"clarity\": \"unclear\"}\n"
     ]
    }
   ],
   "source": [
    "var1 = 'json{\"clarity\": \"unclear\"}'\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e915f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'json{\"clarity\": \"unclear\"}'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "930fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JsonOutputParser().invoke(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "989e242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8116df25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2764627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the analysis of the message:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"clarity\": \"unclear\",\n",
      "  \"grammar_quality\": \"minor issues\",\n",
      "  \"tone\": \"informal\",\n",
      "  \"suggestions\": [\n",
      "    \"For clarity, please specify what report you are referring to.\",\n",
      "    \"Consider rephrasing to 'I would greatly appreciate it if you could send me the report by tomorrow' for a clearer tone.\",\n",
      "    \"There is a misplaced period at the end of the message. For better grammar, consider ending the message with a period or a question mark.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "This analysis suggests that the message is unclear due to the lack of specifics about the report. The tone is informal, which may be suitable for a personal or casual conversation but may not be suitable for a formal request. There are minor grammatical issues, such as the misplaced period at the end of the message.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "001ac77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unclear'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['clarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4adf",
   "metadata": {},
   "source": [
    "### Chain (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b49e8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clarity': 'clear',\n",
       " 'grammar_quality': 'correct',\n",
       " 'tone': 'informal',\n",
       " 'suggestions': ['Consider including more details about the report or the expected format to ensure you receive the correct information.']}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | JsonOutputParser()\n",
    "\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c72bd",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bec49c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_str = \"Hello world, this is the tone - {tone}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fd0305ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_str.format(tone = \"Happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cd19403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tone = \"Happy\"\n",
    "# my_str = f\"Hello world, this is the tone - {tone}\"\n",
    "# print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50726b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = \"\"\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\n",
    "Ensure proper sentence structure, clarity, and readability.\n",
    "\n",
    "Tone Adjustment: {tone}\n",
    "\n",
    "Communication Style: {communication_style}\n",
    "\n",
    "Retain the core message of the original text while making the necessary corrections and tone adjustments.\n",
    "Suggest appropriate phrasing and formatting based on the tone and communication style.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebc6f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\n",
      "Ensure proper sentence structure, clarity, and readability.\n",
      "\n",
      "Tone Adjustment: Happy\n",
      "\n",
      "Communication Style: Formal\n",
      "\n",
      "Retain the core message of the original text while making the necessary corrections and tone adjustments.\n",
      "Suggest appropriate phrasing and formatting based on the tone and communication style.\n"
     ]
    }
   ],
   "source": [
    "print(my_str.format(tone=\"Happy\", communication_style = \"Formal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f421e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_message_template = \"\"\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\n",
    "Ensure proper sentence structure, clarity, and readability.\n",
    "\n",
    "Tone Adjustment: {tone}\n",
    "\n",
    "Communication Style: {communication_style}\n",
    "\n",
    "Retain the core message of the original text while making the necessary corrections and tone adjustments.\n",
    "Suggest appropriate phrasing and formatting based on the tone and communication style.\"\"\"\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", system_message_template),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ca2144f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communication_style', 'tone', 'user_input']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "099b2d22-e7bf-4b33-9701-c8e409d958b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does this work without LCEL = LangChain Expression LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66057ef7-e330-485b-8c52-d1405576e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = 'Rewrite the message in a professional, polite, and structured manner. \\\n",
    "Suitable for business emails, official reports, or any context requiring formality and respect.'\n",
    "\n",
    "communication_style = 'Messages should be clear, structured, and formal or neutral depending on the context. \\\n",
    "Introductions, conclusions, and appropriate sign-offs should be added if missing.'\n",
    "\n",
    "user_input = \"\"\"Can u send me the data by eod pls?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ddc6ca8-67f0-4ee4-ba7b-cf9099d6dda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\nEnsure proper sentence structure, clarity, and readability.\\n\\nTone Adjustment: Rewrite the message in a professional, polite, and structured manner. Suitable for business emails, official reports, or any context requiring formality and respect.\\n\\nCommunication Style: Messages should be clear, structured, and formal or neutral depending on the context. Introductions, conclusions, and appropriate sign-offs should be added if missing.\\n\\nRetain the core message of the original text while making the necessary corrections and tone adjustments.\\nSuggest appropriate phrasing and formatting based on the tone and communication style.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can u send me the data by eod pls?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First step\n",
    "formatted_template = template.invoke({\"communication_style\": communication_style,\n",
    "    \"tone\":tone,\n",
    "    \"user_input\":user_input\n",
    "})\n",
    "formatted_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18ad8548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.ChatPromptValue"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(formatted_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9622dac8-0bab-4986-8a25-64c0cab7b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second step\n",
    "response = llm.invoke(formatted_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "528f8feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5df50f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a rewritten version of the message in a professional, polite, and structured manner:\\n\\nDear [Recipient],\\n\\nI would appreciate it if you could provide me with the requested data by the end of the day (EOD) today. If there are any issues or concerns that may affect the timely delivery of the data, please let me know as soon as possible so we can discuss alternative arrangements.\\n\\nThank you for your prompt attention to this matter.\\n\\nBest regards,\\n[Your Name]\\n\\nAlternatively, if you prefer a more concise version:\\n\\nDear [Recipient],\\n\\nCould you please provide the requested data by the end of the day today? If you anticipate any delays, kindly inform me as soon as possible so we can discuss alternative arrangements.\\n\\nThank you for your cooperation.\\n\\nBest regards,\\n[Your Name]\\n\\nNote that the original message is quite brief, so the rewritten versions have been kept concise while maintaining a professional tone.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0db53fcb-09f4-4176-b918-a7540341816b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a rewritten version of the message in a professional, polite, and structured manner:\\n\\nDear [Recipient],\\n\\nI would appreciate it if you could provide me with the requested data by the end of the day (EOD) today. If there are any issues or concerns that may affect the timely delivery of the data, please let me know as soon as possible so we can discuss alternative arrangements.\\n\\nThank you for your prompt attention to this matter.\\n\\nBest regards,\\n[Your Name]\\n\\nAlternatively, if you prefer a more concise version:\\n\\nDear [Recipient],\\n\\nCould you please provide the requested data by the end of the day today? If you anticipate any delays, kindly inform me as soon as possible so we can discuss alternative arrangements.\\n\\nThank you for your cooperation.\\n\\nBest regards,\\n[Your Name]\\n\\nNote that the original message is quite brief, so the rewritten versions have been kept concise while maintaining a professional tone.\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Third step\n",
    "final_parsed_result = StrOutputParser().invoke(response)\n",
    "final_parsed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "67897832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #With LCEL\n",
    "# proof_read_chain = template | llm ##RunnableSequence\n",
    "# final_response = proof_read_chain.invoke(\n",
    "#     {\"communication_style\": communication_style,\n",
    "#     \"tone\":tone,\n",
    "#     \"user_input\":user_input\n",
    "# })\n",
    "# final_response\n",
    "# type(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "423f262c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['communication_style', 'tone', 'user_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['communication_style', 'tone'], input_types={}, partial_variables={}, template='Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\nEnsure proper sentence structure, clarity, and readability.\\n\\nTone Adjustment: {tone}\\n\\nCommunication Style: {communication_style}\\n\\nRetain the core message of the original text while making the necessary corrections and tone adjustments.\\nSuggest appropriate phrasing and formatting based on the tone and communication style.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11670de50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x116b84910>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With LCEL\n",
    "proof_read_chain = template | llm | StrOutputParser()\n",
    "proof_read_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fc770e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(proof_read_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d0dfa75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a rewritten version of the message in a professional and polite tone:\\n\\nDear [Recipient],\\n\\nI kindly request that you provide me with the necessary data by the end of the day (EOD) today. Please let me know if this deadline is feasible and if there are any issues that may delay the data delivery.\\n\\nI appreciate your prompt attention to this matter and look forward to receiving the data by the designated time.\\n\\nThank you for your cooperation and assistance.\\n\\nBest regards,\\n[Your Name]\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response = proof_read_chain.invoke(\n",
    "    {\"communication_style\": communication_style,\n",
    "    \"tone\":tone,\n",
    "    \"user_input\":user_input\n",
    "})\n",
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "69f84976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof_read_chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c21138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_map = {\n",
    "    \"Formal\": \"Rewrite the message in a professional, polite, and structured manner. Suitable for business emails, official reports, or any context requiring formality and respect.\",\n",
    "    \"Informal\": \"Rewrite in a casual, friendly, and conversational style. Appropriate for personal communications, friendly chats, or informal emails.\",\n",
    "    \"Neutral\": \"Rewrite in a balanced tone that is neither overly formal nor too casual. Suitable for most general communications where a middle-ground tone is required.\"\n",
    "}\n",
    "communication_style_map = {\n",
    "    \"Email\": \"Messages should be clear, structured, and formal or neutral depending on the context. Introductions, conclusions, and appropriate sign-offs should be added if missing.\",\n",
    "    \"General\": \"This covers most forms of communication and will aim for clarity and coherence. The tone can vary as per the user's choice.\",\n",
    "    \"Instant Messaging\": \"Focus on brevity, clarity, and informality, using conversational phrasing suitable for quick back-and-forth exchanges.\",\n",
    "    \"Business Instant Messaging\": \"Maintain a professional but conversational tone. Messages should be concise and efficient, avoiding unnecessary formalities but keeping the language respectful.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cef8565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a rewritten version of your message in a professional, polite, and structured tone:\n",
      "\n",
      "\"Dear [Recipient],\n",
      "\n",
      "I would greatly appreciate it if you could provide me with the requested data by the end of the day (EOD) today. Could you please ensure that the data is sent to me in a timely manner so that I can review and utilize it accordingly?\n",
      "\n",
      "Thank you for your prompt attention to this matter.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\"\n",
      "\n",
      "I made the following changes to the original message:\n",
      "\n",
      "* Added a formal greeting and sign-off\n",
      "* Changed the tone to be polite and professional\n",
      "* Structured the message to be clear and concise\n",
      "* Retained the core message of the original text while making necessary corrections\n"
     ]
    }
   ],
   "source": [
    "tone = \"Formal\" # Formal, Informal, Neutral\n",
    "communication_style = \"Email\" # Email, General, Instant Messaging, Business Instant Messaging\n",
    "user_input = \"\"\"Can u send me the data by eod pls?\"\"\"\n",
    "\n",
    "chain_output = proof_read_chain.invoke(dict(\n",
    "    tone=tone_map[tone],\n",
    "    communication_style = communication_style_map[communication_style],\n",
    "    user_input = user_input\n",
    "))\n",
    "print(chain_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
