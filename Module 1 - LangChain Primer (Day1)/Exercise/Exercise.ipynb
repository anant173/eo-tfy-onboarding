{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Sentiment Analysis and Key Insights Extraction from Ford Car Reviews\n",
    "\n",
    "### **Problem Statement:**\n",
    "You have been provided with a dataset containing Ford car reviews. Your task is to use LangChain and the concepts you’ve learned to perform the following tasks:\n",
    "\n",
    "1. **Sentiment Analysis**: Analyze the sentiment of each review, categorize it as positive, neutral, or negative, and store the result.\n",
    "2. **Key Insights Extraction**: Extract key pieces of information from each review, such as the pros and cons mentioned, and the specific features the reviewer liked or disliked (e.g., vehicle performance, comfort, price).\n",
    "\n",
    "You will build a LangChain-based solution that leverages language models to automatically extract this information and provide a structured summary of the reviews. \n",
    "\n",
    "---\n",
    "### **Steps to Solve:**\n",
    "\n",
    "#### **Step 1: Load the Dataset**\n",
    "- The dataset file is named `ford_car_reviews.csv` and is sourced from Kaggle: [Edmunds Consumer Car Ratings and Reviews](https://www.kaggle.com/datasets/ankkur13/edmundsconsumer-car-ratings-and-reviews).\n",
    "- For this exercise, **limit the data to the first 25 records**. This can be achieved by using `df.head(25)` or `df.iloc[:25]` when loading the data into a DataFrame.\n",
    "\n",
    "#### **Step 2: Define the Sentiment Analysis Task**\n",
    "- Use LangChain to create a pipeline to classify the sentiment of each review.\n",
    "- Define prompts that can guide the model to evaluate the sentiment. For example:\n",
    "  - \"Given the following car review, classify the sentiment as positive, neutral, or negative.\"\n",
    "\n",
    "#### **Step 3: Key Insights Extraction**\n",
    "- Use LangChain to create a pipeline to extract pros, cons, and notable features from each review. Define prompts such as:\n",
    "  - \"What are the pros and cons of the vehicle described in the following review?\"\n",
    "  - \"What specific features of the vehicle does the reviewer like or dislike?\"\n",
    "\n",
    "#### **Step 4: Update the DataFrame with New Information**\n",
    "- Run the pipeline for each review and collect the sentiment and insights.\n",
    "- Once the analysis and extraction are complete, update the original DataFrame with additional columns to include:\n",
    "  - Sentiment (positive, neutral, negative)\n",
    "  - Pros\n",
    "  - Cons\n",
    "  - Liked_Features\n",
    "  - Disliked_Features\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Job Postings Analysis - Role Categorization and Requirements Extraction (55 marks)\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "Using a provided dataset of job postings, your goal is to use LangChain and an LLM to automatically analyze each posting and extract structured information.\n",
    "1.  **Job Category Classification**: Classify the job role into a broad category like Technology/IT, Finance, Marketing, or Healthcare.\n",
    "2.  **Key Requirements Extraction**: Extract specific requirements from the job description, including:\n",
    "    * **Required Skills/Technologies**: Identify specific skills, programming languages, or tools mentioned (e.g., Python, project management).\n",
    "    * **Education Level**: Identify any required or preferred education levels (e.g., Bachelor's degree, MBA).\n",
    "    * **Experience**: Identify mentions of required experience, such as years of experience or a specific level (e.g., \"3+ years experience\" or \"senior-level\").\n",
    "\n",
    "The final output should augment each job posting with a category label and fields detailing the extracted requirements.\n",
    "\n",
    "**Steps to Solve:**\n",
    "\n",
    "* **Step 1: Load the Dataset**\n",
    "    * Use the provided job postings dataset, loading it into a DataFrame.\n",
    "    * Limit the data to the first 25 job postings to keep processing feasible.\n",
    "    * The expected output is a loaded dataframe.\n",
    "* **Step 2: Define the Job Category Classification Task**\n",
    "    * Develop a prompt to classify the job posting into a broad category.\n",
    "    * A sample prompt is: \"Given the following job title and description, categorize the job into one of the following domains: Technology/IT, Finance, Marketing, Healthcare, Education, Others.\"\n",
    "    * The LLM should return a single category label.\n",
    "    * The expected output is a demonstration of this working for a sample data point.\n",
    "* **Step 3: Define the Requirements Extraction Task**\n",
    "    * Create prompts to extract key requirements: skills, education, and experience.\n",
    "    * You can use separate prompts for each sub-task or a single composite prompt.\n",
    "    * The expected output is a demonstration of this working for a sample data point.\n",
    "* **Step 4: Apply the LLM Chain to Each Job Posting**\n",
    "    * Loop through each job posting in the DataFrame.\n",
    "    * For each entry, feed the job title/description into the classification and extraction prompts.\n",
    "    * Make sure to handle cases where information is not mentioned, such as outputting \"Not specified\" or null.\n",
    "    * The expected output is a Pandas dataframe with all the required additional columns.\n",
    "* **Step 5: Update the DataFrame with New Columns**\n",
    "    * Add new columns to the DataFrame for the outputs, such as **Predicted Category**, **Required Skills**, **Education Required**, and **Experience Required**.\n",
    "    * Fill these columns with the LLM's output for each posting.\n",
    "    * The expected output is a final Pandas dataframe containing all original and new columns.\n",
    "\n",
    "### **Example Output in JSON (should be a merged Pandas dataframe finally):**\n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "\"Job_Title\": \"Senior Data Analyst\",\n",
    "\"Job_Description\": \"We are seeking a Senior Data Analyst to join our team...\n",
    "Responsibilities include analyzing sales data, creating dashboards, and reporting\n",
    "insights. **Requirements:** 5+ years experience in data analysis, proficiency in\n",
    "SQL and Python, familiarity with BI tools. Bachelor's degree in Finance,\n",
    "Statistics, or related field required. Excellent communication skills and\n",
    "attention to detail are a must.\",\n",
    "\"Predicted_Category\": \"Finance/Analytics\",\n",
    "\"Required_Skills\": [\"SQL\", \"Python\", \"Business Intelligence tools\", \"data\n",
    "analysis\"],\n",
    "\"Education_Required\": \"Bachelor’s degree (Finance, Statistics, or related)\",\n",
    "\"Experience_Required\": \"5+ years\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Bonus (optional)\n",
    "\n",
    "Complete the analysis for all rows in the dataset. Note that using Ollama is advised over Groq to avoid rate limits, and you should balance inference speed with accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
